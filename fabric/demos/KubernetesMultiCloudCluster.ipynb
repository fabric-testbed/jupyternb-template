{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook shows how to use Orchestrator APIs for user experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from fabric_cm.credmgr.credmgr_proxy import CredmgrProxy\n",
    "from fabric_cf.orchestrator.orchestrator_proxy import OrchestratorProxy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "credmgr_host = os.environ['FABRIC_CREDMGR_HOST']\n",
    "credmgr_proxy = CredmgrProxy(credmgr_host=credmgr_host)\n",
    "orchestrator_host = os.environ['FABRIC_ORCHESTRATOR_HOST']\n",
    "orchestrator_proxy = OrchestratorProxy(orchestrator_host=orchestrator_host)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fabric Tokens\n",
    "Fabric has 2 kinds of tokens:<br>\n",
    "- Identity : required for Control/Measurement Framework APIs. Identity Token is valid upto an hour.\n",
    "- Refresh : required to generate new Identity Tokens valid. Refresh Token is valid for 24 hours.\n",
    "\n",
    "Fabric Identity token is required for Control/Measurement Framework APIs.<br>\n",
    "\n",
    "When user logins to Jupyterhub after authenticating against CILogon, OIDC refresh token is derived. <br>\n",
    "This token is available as the environment variable `CILOGON_REFRESH_TOKEN`.<br>\n",
    "\n",
    "On the first login, we use `CILOGON_REFRESH_TOKEN` to generate new Fabric Identity Token and Fabric Refresh Token.<br>\n",
    "For any subsequent use, we use Fabric Refresh Token. On every refresh, Fabric Refresh Token is changed and updated.<br>\n",
    "\n",
    "NOTE: These steps are required for any experiments on Fabric Testbed.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no stored variable or alias fabric_refresh_token\n",
      "Stored 'fabric_refresh_token' (str)\n",
      "Fabric Refresh Token NB2HI4DTHIXS6Y3JNRXWO33OFZXXEZZPN5QXK5DIGIXTEZBVGMZDQODCGBRTANDEGA3GIMLBMI4DEYTBMY3TKYTBGE4WMNJ7OR4XAZJ5OJSWM4TFONUFI33LMVXCM5DTHUYTMMJYGY3DEMJYGA3DCMBGOZSXE43JN5XD25RSFYYCM3DJMZSXI2LNMU6TQNRUGAYDAMBQ\n",
      "CILOGON_REFRESH_TOKEN environment variable: NB2HI4DTHIXS6Y3JNRXWO33OFZXXEZZPN5QXK5DIGIXTEZBVGMZDQODCGBRTANDEGA3GIMLBMI4DEYTBMY3TKYTBGE4WMNJ7OR4XAZJ5OJSWM4TFONUFI33LMVXCM5DTHUYTMMJYGY3DEMJYGA3DCMBGOZSXE43JN5XD25RSFYYCM3DJMZSXI2LNMU6TQNRUGAYDAMBQ\n"
     ]
    }
   ],
   "source": [
    "not_found=False\n",
    "fabric_refresh_token=None\n",
    "%store -r fabric_refresh_token\n",
    "\n",
    "if fabric_refresh_token is None:\n",
    "    fabric_refresh_token=os.environ['CILOGON_REFRESH_TOKEN']\n",
    "    %store fabric_refresh_token\n",
    "print(\"Fabric Refresh Token {}\".format(fabric_refresh_token))\n",
    "print(\"CILOGON_REFRESH_TOKEN environment variable: {}\".format(os.environ['CILOGON_REFRESH_TOKEN']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get new Fabric Identity Token and update Fabric Refresh Token\n",
    "\n",
    "Users can request tokens with different Project and Scopes by altering `project_name` and `scope` parameters in the refresh call below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Tokens received: {\"id_token\": \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImtpZCI6ImI0MTUxNjcyMTExOTFlMmUwNWIyMmI1NGIxZDNiNzY2N2U3NjRhNzQ3NzIyMTg1ZTcyMmU1MmUxNDZmZTQzYWEifQ.eyJlbWFpbCI6Im1pbmF3bUBidS5lZHUiLCJjZXJ0X3N1YmplY3RfZG4iOiIvREM9b3JnL0RDPWNpbG9nb24vQz1VUy9PPUJvc3RvbiBVbml2ZXJzaXR5L0NOPU1pbmEgV2lsbGlhbSBNb3Jjb3MgQjQxMzUwNzg3IiwiaWRwIjoiaHR0cHM6Ly9zaGliLmJ1LmVkdS9pZHAvc2hpYmJvbGV0aCIsImlkcF9uYW1lIjoiQm9zdG9uIFVuaXZlcnNpdHkiLCJlcHBuIjoibWluYXdtQGJ1LmVkdSIsImVwdGlkIjoiaHR0cHM6Ly9zaGliLmJ1LmVkdS9pZHAvc2hpYmJvbGV0aCFodHRwczovL2NpbG9nb24ub3JnL3NoaWJib2xldGghUmZSTTBqUWdkYWJHbWFNZmRkRUVZZVlHRTJzPSIsImFmZmlsaWF0aW9uIjoic3R1ZGVudEBidS5lZHU7bWVtYmVyQGJ1LmVkdSIsIm5hbWUiOiJNaW5hIFdpbGxpYW0gTW9yY29zIiwiYWNyIjoiaHR0cHM6Ly9zaGliLmJ1LmVkdS9zaW5nbGUiLCJlbnRpdGxlbWVudCI6Imh0dHA6Ly9pYW0uYnUuZWR1L2lkaW5mby84MDtodHRwOi8vaWFtLmJ1LmVkdS9tZW1iZXIvY2FzO2h0dHA6Ly9pYW0uYnUuZWR1L3JlZy9jb2xsZWdlL2dycztodHRwOi8vaWFtLmJ1LmVkdS9yZWcvY29sbGVnZS9jYXMiLCJpc3MiOiJodHRwczovL2NpbG9nb24ub3JnIiwic3ViIjoiaHR0cDovL2NpbG9nb24ub3JnL3NlcnZlckIvdXNlcnMvNDEzNTA3ODciLCJhdWQiOiJjaWxvZ29uOi9jbGllbnRfaWQvMWYxMWY4MjllYzFmNGYyMjMzNThmNDNiMmM2MDdiODQiLCJ0b2tlbl9pZCI6Imh0dHBzOi8vY2lsb2dvbi5vcmcvb2F1dGgyL2lkVG9rZW4vMmZjNDljOWM2YzMxZGY0YmMwNjI4NmUwZWFjNTZmYzYvMTYxODY2MjE3OTk0MCIsImF1dGhfdGltZSI6MTYxODY2MjE3OSwiZXhwIjoxNjE4NjY1OTUwLCJpYXQiOjE2MTg2NjIzNTAsInByb2plY3RzIjp7IlN0dWRlbnQgVGVzdGluZyI6WyJzdHVkZW50cyIsInRlc3RpbmciXX0sInJvbGVzIjpbImZhYnJpYy1hY3RpdmUtdXNlcnMiLCJlM2Q1ZDM3Mi03YjMwLTQ2YTUtOWI1OS0zOWExZWM0MDY2MGUtcG0iXSwic2NvcGUiOiJhbGwifQ.IRLxfRoSLP_IHA7Ua_JaYm4CJuEGs6M_yUnIfElNPapr16WWhtO-LCKYiQBfQDa1JZNaEilkvOi5HfL02_GoQ60TCWB0q9IxArMLhXmUWUSy2YbNez2eshGfMZTVneOrqAOHZ0PP7_LJuiaRUTy9DZ_e3tjA5tqL_UprKfkZtvvWd4zFhDbB-9VucinWtbOh155XseyPvIuVCd8WuI5hrA1yZsgJe5gv3nWxCM01SdzlMo-VVxQ5sGJErY7Z1eLTU4-nhU4kZSpOS0Z9YGkWGeuWgX6xSnJnZpfR3i4IXJCSnjE9TAyKYRz7KNyTjbslGluLpsMizMjsWrhMFG8kArChPfgxPmicAi2cMcJH0oCnKMxJWlNNZtBomGv8UWcscZg-SzEoKWFV4v6YZT7eV6ETFdd_my-wA6r779_1cnpbE523w8Tg4xIRmG-DOMJ-c9U28Lwu80nqwLfVfRq2U7tA342VKAvb23PUuR9QnQvwhF88YyFl6GI17nwMBfGYif0Ow0f2zllQ95Xj-NZPE2BdD0Mtg-gS2w-vREGrwpubhlwHoxXy8_Gtu2xA7cYkaLLuj1RAY6xejK49wzQc5CbJXvKe8oFn3yf7zugvY1_bGEkG0YRt8Gs2xbYNAnVHdeLsnrV67XKusTrBUgkQ8h76JAfc9etgyyak-2i4dbY\", \"refresh_token\": \"NB2HI4DTHIXS6Y3JNRXWO33OFZXXEZZPN5QXK5DIGIXTGN3FGM2WMNZSGVSDEY3GGQ2DSNBSMU2GIMRUMJTGMZJXGQ3TCYJ7OR4XAZJ5OJSWM4TFONUFI33LMVXCM5DTHUYTMMJYGY3DEMZUHA2DSNBGOZSXE43JN5XD25RSFYYCM3DJMZSXI2LNMU6TQNRUGAYDAMBQ\"}\n",
      "\n",
      "New Refresh Token: NB2HI4DTHIXS6Y3JNRXWO33OFZXXEZZPN5QXK5DIGIXTGN3FGM2WMNZSGVSDEY3GGQ2DSNBSMU2GIMRUMJTGMZJXGQ3TCYJ7OR4XAZJ5OJSWM4TFONUFI33LMVXCM5DTHUYTMMJYGY3DEMZUHA2DSNBGOZSXE43JN5XD25RSFYYCM3DJMZSXI2LNMU6TQNRUGAYDAMBQ\n",
      "\n",
      "Stored new Refresh Token\n",
      "Stored 'fabric_refresh_token' (str)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    refresh_res = credmgr_proxy.refresh(project_name='all', scope='all', refresh_token=fabric_refresh_token)\n",
    "    print(\"New Tokens received: {}\".format(json.dumps(refresh_res)))\n",
    "    fabric_id_token=refresh_res['id_token']\n",
    "    fabric_refresh_token=refresh_res['refresh_token']\n",
    "    print()\n",
    "    print(\"New Refresh Token: {}\".format(fabric_refresh_token))\n",
    "    print()\n",
    "    print(\"Stored new Refresh Token\")\n",
    "    %store fabric_refresh_token\n",
    "except Exception as e:\n",
    "    print(\"Exception occurred while getting tokens:{}\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orchestrator API example to query for available resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Status.OK\n",
      "Toplogy: LBNL: { cpu: 6/6, core: 92/96, ram: 1472/1536G, disk: 109100/109600G, unit: 3/3, }\n",
      "\tComponents:\n",
      "\t\tNVME-P4510:  NVME P4510 { disk: 10000/10000G, unit: 10/10, }\n",
      "\t\tGPU-RTX6000:  GPU RTX6000 { unit: 2/2, }\n",
      "\t\tGPU-Tesla T4:  GPU Tesla T4 { unit: 3/4, }\n",
      "\t\tSharedNIC-ConnectX-6:  SharedNIC ConnectX-6 { unit: 3/3, }\n",
      "\t\tSmartNIC-ConnectX-6:  SmartNIC ConnectX-6 { unit: 2/2, }\n",
      "\t\tSmartNIC-ConnectX-5:  SmartNIC ConnectX-5 { unit: 2/2, }\n",
      "\tSite Interfaces:\n",
      "RENC: { cpu: 6/6, core: 92/96, ram: 1472/1536G, disk: 109100/109600G, unit: 3/3, }\n",
      "\tComponents:\n",
      "\t\tSmartNIC-ConnectX-5:  SmartNIC ConnectX-5 { unit: 1/2, }\n",
      "\t\tNVME-P4510:  NVME P4510 { disk: 10000/10000G, unit: 10/10, }\n",
      "\t\tGPU-RTX6000:  GPU RTX6000 { unit: 2/2, }\n",
      "\t\tGPU-Tesla T4:  GPU Tesla T4 { unit: 4/4, }\n",
      "\t\tSharedNIC-ConnectX-6:  SharedNIC ConnectX-6 { unit: 3/3, }\n",
      "\t\tSmartNIC-ConnectX-6:  SmartNIC ConnectX-6 { unit: 2/2, }\n",
      "\tSite Interfaces:\n",
      "UKY: { cpu: 6/6, core: 96/96, ram: 1536/1536G, disk: 109600/109600G, unit: 3/3, }\n",
      "\tComponents:\n",
      "\t\tNVME-P4510:  NVME P4510 { disk: 10000/10000G, unit: 10/10, }\n",
      "\t\tGPU-RTX6000:  GPU RTX6000 { unit: 2/2, }\n",
      "\t\tGPU-Tesla T4:  GPU Tesla T4 { unit: 4/4, }\n",
      "\t\tSharedNIC-ConnectX-6:  SharedNIC ConnectX-6 { unit: 3/3, }\n",
      "\t\tSmartNIC-ConnectX-6:  SmartNIC ConnectX-6 { unit: 2/2, }\n",
      "\t\tSmartNIC-ConnectX-5:  SmartNIC ConnectX-5 { unit: 2/2, }\n",
      "\tSite Interfaces:\n",
      "Links:\n"
     ]
    }
   ],
   "source": [
    "status, advertised_topology = orchestrator_proxy.resources(token=fabric_id_token)\n",
    "\n",
    "print(f\"Status: {status}\")\n",
    "print(f\"Toplogy: {advertised_topology}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "advertised_topology.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Status Status.OK\n",
      "Reservations created [{\n",
      "    \"graph_node_id\": \"50b46843-c5db-4486-8d99-303b00a0c932\",\n",
      "    \"join_state\": \"None_\",\n",
      "    \"lease_end\": \"2021-04-18 12:26:43\",\n",
      "    \"reservation_id\": \"20e5b9d8-50cd-4ad9-8dc1-930e0772cc4e\",\n",
      "    \"reservation_state\": \"Unknown\",\n",
      "    \"resource_type\": \"VM\",\n",
      "    \"slice_id\": \"8a8bfacd-2e71-427f-839f-a79ab85515ab\"\n",
      "}, {\n",
      "    \"graph_node_id\": \"7fe87e36-e5e8-48e5-a094-ca4ef1d8b40b\",\n",
      "    \"join_state\": \"None_\",\n",
      "    \"lease_end\": \"2021-04-18 12:26:44\",\n",
      "    \"reservation_id\": \"d0cf0b1c-58da-4a5c-9874-724772670441\",\n",
      "    \"reservation_state\": \"Unknown\",\n",
      "    \"resource_type\": \"VM\",\n",
      "    \"slice_id\": \"8a8bfacd-2e71-427f-839f-a79ab85515ab\"\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "import fim.user as fu\n",
    "# Create topology\n",
    "t = fu.ExperimentTopology()\n",
    "\n",
    "# Add node\n",
    "n1 = t.add_node(name='n1', site='RENC')\n",
    "\n",
    "# Set capacities\n",
    "cap = fu.Capacities()\n",
    "cap.set_fields(core=4, ram=64, disk=500)\n",
    "\n",
    "# Set Properties\n",
    "n1.set_properties(capacities=cap, image_type='qcow2', image_ref='default_ubuntu_20')\n",
    "\n",
    "# Add PCI devices\n",
    "n1.add_component(ctype=fu.ComponentType.SmartNIC, model='ConnectX-5', name='nic1')\n",
    "\n",
    "# Add node\n",
    "n2 = t.add_node(name='n2', site='LBNL')\n",
    "\n",
    "# Set properties\n",
    "n2.set_properties(capacities=cap, image_type='qcow2', image_ref='default_ubuntu_20')\n",
    "\n",
    "# Add PCI devices\n",
    "n2.add_component(ctype=fu.ComponentType.GPU, model='Tesla T4', name='nic2')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Add node\n",
    "# n3 = t.add_node(name='n3', site='LBNL')\n",
    "\n",
    "# # Set properties\n",
    "# n3.set_properties(capacities=cap, image_type='qcow2', image_ref='default_centos_8')\n",
    "\n",
    "# # Add PCI devices\n",
    "# n3.add_component(ctype=fu.ComponentType.GPU, model='Tesla T4', name='nic3')\n",
    "\n",
    "# Generate Slice Graph\n",
    "slice_graph = t.serialize()\n",
    "\n",
    "ssh_key = None\n",
    "with open (\"/home/fabric/.ssh/id_rsa.pub\", \"r\") as myfile:\n",
    "    ssh_key=myfile.read()\n",
    "    ssh_key=ssh_key.strip()\n",
    "\n",
    "# Request slice from Orchestrator\n",
    "status, reservations = orchestrator_proxy.create(token=fabric_id_token, slice_name='JupyterSlice2', slice_graph=slice_graph, ssh_key=ssh_key)\n",
    "\n",
    "print(\"Response Status {}\".format(status))\n",
    "print(\"Reservations created {}\".format(reservations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Slice ID from output of the above command\n",
    "slice_id=reservations[0].slice_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Status Status.OK\n",
      "Slices [{\n",
      "    \"graph_id\": \"d57a848a-e80d-431c-a090-70858f53760a\",\n",
      "    \"slice_id\": \"8a8bfacd-2e71-427f-839f-a79ab85515ab\",\n",
      "    \"slice_name\": \"JupyterSlice2\",\n",
      "    \"slice_state\": \"StableOK\"\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "status, slices = orchestrator_proxy.slices(token=fabric_id_token)\n",
    "\n",
    "print(\"Response Status {}\".format(status))\n",
    "print(\"Slices {}\".format(slices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Status Status.OK\n",
      "Response received n1[VM]: { core: 4, ram: 64G, disk: 500G, }\n",
      "n2[VM]: { core: 4, ram: 64G, disk: 500G, }\n",
      "Links:\n"
     ]
    }
   ],
   "source": [
    "status, slice_obj = orchestrator_proxy.get_slice(token=fabric_id_token, slice_id=slice_id)\n",
    "\n",
    "print(\"Response Status {}\".format(status))\n",
    "print(\"Response received {}\".format(slice_obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "slice_obj.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Slivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Status Status.OK\n",
      "Reservations [{\n",
      "    \"capacities\": \"{\\\"core\\\": 4, \\\"disk\\\": 500, \\\"ram\\\": 64}\",\n",
      "    \"graph_node_id\": \"50b46843-c5db-4486-8d99-303b00a0c932\",\n",
      "    \"join_state\": \"NoJoin\",\n",
      "    \"labels\": \"\",\n",
      "    \"lease_end\": \"2021-04-18 12:26:43\",\n",
      "    \"management_ip\": \"152.54.15.33\",\n",
      "    \"name\": \"n1\",\n",
      "    \"reservation_id\": \"20e5b9d8-50cd-4ad9-8dc1-930e0772cc4e\",\n",
      "    \"reservation_state\": \"Active\",\n",
      "    \"resource_type\": \"VM\",\n",
      "    \"site\": \"RENC\",\n",
      "    \"slice_id\": \"8a8bfacd-2e71-427f-839f-a79ab85515ab\"\n",
      "}, {\n",
      "    \"capacities\": \"{\\\"core\\\": 4, \\\"disk\\\": 500, \\\"ram\\\": 64}\",\n",
      "    \"graph_node_id\": \"7fe87e36-e5e8-48e5-a094-ca4ef1d8b40b\",\n",
      "    \"join_state\": \"NoJoin\",\n",
      "    \"labels\": \"\",\n",
      "    \"lease_end\": \"2021-04-18 12:26:44\",\n",
      "    \"management_ip\": \"198.129.61.38\",\n",
      "    \"name\": \"n2\",\n",
      "    \"reservation_id\": \"d0cf0b1c-58da-4a5c-9874-724772670441\",\n",
      "    \"reservation_state\": \"Active\",\n",
      "    \"resource_type\": \"VM\",\n",
      "    \"site\": \"LBNL\",\n",
      "    \"slice_id\": \"8a8bfacd-2e71-427f-839f-a79ab85515ab\"\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "status, reservations = orchestrator_proxy.slivers(token=fabric_id_token, slice_id=slice_id)\n",
    "\n",
    "print(\"Response Status {}\".format(status))\n",
    "print(\"Reservations {}\".format(reservations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Sliver ID from output of the above command by capturing reservation_id\n",
    "sliver_id=reservations[0].reservation_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Sliver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Status Status.OK\n",
      "Reservation [{\n",
      "    \"capacities\": \"{\\\"core\\\": 4, \\\"disk\\\": 500, \\\"ram\\\": 64}\",\n",
      "    \"graph_node_id\": \"50b46843-c5db-4486-8d99-303b00a0c932\",\n",
      "    \"join_state\": \"NoJoin\",\n",
      "    \"labels\": \"\",\n",
      "    \"lease_end\": \"2021-04-18 12:26:43\",\n",
      "    \"management_ip\": \"152.54.15.33\",\n",
      "    \"name\": \"n1\",\n",
      "    \"reservation_id\": \"20e5b9d8-50cd-4ad9-8dc1-930e0772cc4e\",\n",
      "    \"reservation_state\": \"Active\",\n",
      "    \"resource_type\": \"VM\",\n",
      "    \"site\": \"RENC\",\n",
      "    \"slice_id\": \"8a8bfacd-2e71-427f-839f-a79ab85515ab\"\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "status, reservation = orchestrator_proxy.slivers(token=fabric_id_token, slice_id=slice_id, sliver_id=sliver_id)\n",
    "\n",
    "print(\"Response Status {}\".format(status))\n",
    "print(\"Reservation {}\".format(reservation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slice Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Status Status.OK\n",
      "Slice Status {\n",
      "    \"graph_id\": \"d57a848a-e80d-431c-a090-70858f53760a\",\n",
      "    \"slice_id\": \"8a8bfacd-2e71-427f-839f-a79ab85515ab\",\n",
      "    \"slice_name\": \"JupyterSlice2\",\n",
      "    \"slice_state\": \"StableOK\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "status, slice_status = orchestrator_proxy.slice_status(token=fabric_id_token, slice_id=slice_id)\n",
    "\n",
    "print(\"Response Status {}\".format(status))\n",
    "print(\"Slice Status {}\".format(slice_status))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliver Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Status Status.OK\n",
      "Reservation Status {\n",
      "    \"capacities\": \"{\\\"core\\\": 4, \\\"disk\\\": 500, \\\"ram\\\": 64}\",\n",
      "    \"graph_node_id\": \"50b46843-c5db-4486-8d99-303b00a0c932\",\n",
      "    \"join_state\": \"NoJoin\",\n",
      "    \"labels\": \"\",\n",
      "    \"lease_end\": \"2021-04-18 12:26:43\",\n",
      "    \"management_ip\": \"152.54.15.33\",\n",
      "    \"name\": \"n1\",\n",
      "    \"notices\": \"Reservation 20e5b9d8-50cd-4ad9-8dc1-930e0772cc4e (Slice JupyterSlice2(8a8bfacd-2e71-427f-839f-a79ab85515ab) Graph Id:d57a848a-e80d-431c-a090-70858f53760a ) is in state [Active,None_]\\n\\nLast ticket update: \\nTicket events: \\nLast ticket update: \\nTicket events: \",\n",
      "    \"reservation_id\": \"20e5b9d8-50cd-4ad9-8dc1-930e0772cc4e\",\n",
      "    \"reservation_state\": \"Active\",\n",
      "    \"resource_type\": \"VM\",\n",
      "    \"site\": \"RENC\",\n",
      "    \"slice_id\": \"8a8bfacd-2e71-427f-839f-a79ab85515ab\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "status, reservation_status = orchestrator_proxy.sliver_status(token=fabric_id_token, slice_id=slice_id, sliver_id=sliver_id)\n",
    "\n",
    "print(\"Response Status {}\".format(status))\n",
    "print(\"Reservation Status {}\".format(reservation_status))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work on the servers start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paramiko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'152.54.15.33'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reservation_status.management_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'152.54.15.33'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reservations[0].management_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'198.129.61.38'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reservations[1].management_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<paramiko.client.SSHClient at 0x7f388c0de4c0>"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = paramiko.RSAKey.from_private_key_file(\"/home/fabric/.ssh/id_rsa\")\n",
    "client1 = paramiko.SSHClient()\n",
    "client1.load_system_host_keys()\n",
    "client1.set_missing_host_key_policy(paramiko.MissingHostKeyPolicy())\n",
    "\n",
    "client1.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "client1.connect(reservations[0].management_ip,username='ubuntu',pkey = key)\n",
    "\n",
    "client1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributor ID:\tUbuntu\n",
      "Description:\tUbuntu 20.04.2 LTS\n",
      "Release:\t20.04\n",
      "Codename:\tfocal\n",
      "\n",
      "No LSB modules are available.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('lsb_release -a')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n",
      "    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n",
      "    inet 127.0.0.1/8 scope host lo\n",
      "       valid_lft forever preferred_lft forever\n",
      "    inet6 ::1/128 scope host \n",
      "       valid_lft forever preferred_lft forever\n",
      "2: ens3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 9000 qdisc fq_codel state UP group default qlen 1000\n",
      "    link/ether fa:16:3e:ec:09:fc brd ff:ff:ff:ff:ff:ff\n",
      "    inet 10.20.4.220/24 brd 10.20.4.255 scope global dynamic ens3\n",
      "       valid_lft 86192sec preferred_lft 86192sec\n",
      "    inet6 fe80::f816:3eff:feec:9fc/64 scope link \n",
      "       valid_lft forever preferred_lft forever\n",
      "3: ens7: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000\n",
      "    link/ether 0c:42:a1:be:8f:e8 brd ff:ff:ff:ff:ff:ff\n",
      "4: ens8: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000\n",
      "    link/ether 0c:42:a1:be:8f:e9 brd ff:ff:ff:ff:ff:ff\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('ip addr')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152.54.15.33\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    12  100    12    0     0     16      0 --:--:-- --:--:-- --:--:--    16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('curl https://ipinfo.io/ip')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<paramiko.client.SSHClient at 0x7f388c05fee0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = paramiko.RSAKey.from_private_key_file(\"/home/fabric/.ssh/id_rsa\")\n",
    "client2 = paramiko.SSHClient()\n",
    "client2.load_system_host_keys()\n",
    "client2.set_missing_host_key_policy(paramiko.MissingHostKeyPolicy())\n",
    "\n",
    "client2.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "client2.connect(reservations[1].management_ip,username='ubuntu',pkey = key)\n",
    "\n",
    "client2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198.129.61.38\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    13  100    13    0     0     74      0 --:--:-- --:--:-- --:--:--    74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client2.exec_command('curl https://ipinfo.io/ip')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152.54.15.33\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    12  100    12    0     0    136      0 --:--:-- --:--:-- --:--:--   136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('curl https://ipinfo.io/ip')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you look at the two cells above. You see that now we have client1 connected to a machine, and client2 connected to another machine. Simple and easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PING 152.54.15.33 (152.54.15.33) 56(84) bytes of data.\n",
      "64 bytes from 152.54.15.33: icmp_seq=1 ttl=55 time=71.9 ms\n",
      "64 bytes from 152.54.15.33: icmp_seq=2 ttl=55 time=71.5 ms\n",
      "64 bytes from 152.54.15.33: icmp_seq=3 ttl=55 time=71.4 ms\n",
      "64 bytes from 152.54.15.33: icmp_seq=4 ttl=55 time=71.4 ms\n",
      "64 bytes from 152.54.15.33: icmp_seq=5 ttl=55 time=71.4 ms\n",
      "64 bytes from 152.54.15.33: icmp_seq=6 ttl=55 time=71.5 ms\n",
      "64 bytes from 152.54.15.33: icmp_seq=7 ttl=55 time=71.5 ms\n",
      "64 bytes from 152.54.15.33: icmp_seq=8 ttl=55 time=71.4 ms\n",
      "64 bytes from 152.54.15.33: icmp_seq=9 ttl=55 time=71.3 ms\n",
      "64 bytes from 152.54.15.33: icmp_seq=10 ttl=55 time=71.4 ms\n",
      "\n",
      "--- 152.54.15.33 ping statistics ---\n",
      "10 packets transmitted, 10 received, 0% packet loss, time 9013ms\n",
      "rtt min/avg/max/mdev = 71.348/71.468/71.930/0.161 ms\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client2.exec_command('ping -c 10 152.54.15.33')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PING 198.129.61.38 (198.129.61.38) 56(84) bytes of data.\n",
      "64 bytes from 198.129.61.38: icmp_seq=1 ttl=50 time=71.3 ms\n",
      "64 bytes from 198.129.61.38: icmp_seq=2 ttl=50 time=71.4 ms\n",
      "64 bytes from 198.129.61.38: icmp_seq=3 ttl=50 time=71.4 ms\n",
      "64 bytes from 198.129.61.38: icmp_seq=4 ttl=50 time=71.4 ms\n",
      "64 bytes from 198.129.61.38: icmp_seq=5 ttl=50 time=71.4 ms\n",
      "64 bytes from 198.129.61.38: icmp_seq=6 ttl=50 time=71.4 ms\n",
      "64 bytes from 198.129.61.38: icmp_seq=7 ttl=50 time=71.4 ms\n",
      "64 bytes from 198.129.61.38: icmp_seq=8 ttl=50 time=71.4 ms\n",
      "64 bytes from 198.129.61.38: icmp_seq=9 ttl=50 time=71.4 ms\n",
      "64 bytes from 198.129.61.38: icmp_seq=10 ttl=50 time=71.4 ms\n",
      "\n",
      "--- 198.129.61.38 ping statistics ---\n",
      "10 packets transmitted, 10 received, 0% packet loss, time 9013ms\n",
      "rtt min/avg/max/mdev = 71.333/71.400/71.434/0.029 ms\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('ping -c 10 198.129.61.38')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ping experiment complete. Both nodes can see each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's start a Kubernetes cluster on those two nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make the node connected to client 1 master."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://security.ubuntu.com/ubuntu focal-security InRelease [109 kB]\n",
      "Get:2 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [619 kB]\n",
      "Get:3 http://security.ubuntu.com/ubuntu focal-security/main Translation-en [126 kB]\n",
      "Get:4 http://security.ubuntu.com/ubuntu focal-security/main amd64 c-n-f Metadata [7436 B]\n",
      "Get:5 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [181 kB]\n",
      "Get:6 http://security.ubuntu.com/ubuntu focal-security/restricted Translation-en [26.8 kB]\n",
      "Get:7 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 c-n-f Metadata [396 B]\n",
      "Get:8 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [551 kB]\n",
      "Get:9 http://security.ubuntu.com/ubuntu focal-security/universe Translation-en [82.1 kB]\n",
      "Get:10 http://security.ubuntu.com/ubuntu focal-security/universe amd64 c-n-f Metadata [10.7 kB]\n",
      "Get:11 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [14.8 kB]\n",
      "Get:12 http://security.ubuntu.com/ubuntu focal-security/multiverse Translation-en [3160 B]\n",
      "Get:13 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 c-n-f Metadata [340 B]\n",
      "Hit:14 http://nova.clouds.archive.ubuntu.com/ubuntu focal InRelease\n",
      "Get:15 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
      "Get:16 http://nova.clouds.archive.ubuntu.com/ubuntu focal-backports InRelease [101 kB]\n",
      "Get:17 http://nova.clouds.archive.ubuntu.com/ubuntu focal/universe amd64 Packages [8628 kB]\n",
      "Get:18 http://nova.clouds.archive.ubuntu.com/ubuntu focal/universe Translation-en [5124 kB]\n",
      "Get:19 http://nova.clouds.archive.ubuntu.com/ubuntu focal/universe amd64 c-n-f Metadata [265 kB]\n",
      "Get:20 http://nova.clouds.archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [144 kB]\n",
      "Get:21 http://nova.clouds.archive.ubuntu.com/ubuntu focal/multiverse Translation-en [104 kB]\n",
      "Get:22 http://nova.clouds.archive.ubuntu.com/ubuntu focal/multiverse amd64 c-n-f Metadata [9136 B]\n",
      "Get:23 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [943 kB]\n",
      "Get:24 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/main Translation-en [216 kB]\n",
      "Get:25 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/main amd64 c-n-f Metadata [13.1 kB]\n",
      "Get:26 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [204 kB]\n",
      "Get:27 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/restricted Translation-en [30.4 kB]\n",
      "Get:28 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/restricted amd64 c-n-f Metadata [440 B]\n",
      "Get:29 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [759 kB]\n",
      "Get:30 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/universe Translation-en [162 kB]\n",
      "Get:31 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/universe amd64 c-n-f Metadata [17.0 kB]\n",
      "Get:32 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [21.6 kB]\n",
      "Get:33 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/multiverse Translation-en [5508 B]\n",
      "Get:34 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 c-n-f Metadata [600 B]\n",
      "Get:35 http://nova.clouds.archive.ubuntu.com/ubuntu focal-backports/main amd64 c-n-f Metadata [112 B]\n",
      "Get:36 http://nova.clouds.archive.ubuntu.com/ubuntu focal-backports/restricted amd64 c-n-f Metadata [116 B]\n",
      "Get:37 http://nova.clouds.archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [4032 B]\n",
      "Get:38 http://nova.clouds.archive.ubuntu.com/ubuntu focal-backports/universe Translation-en [1448 B]\n",
      "Get:39 http://nova.clouds.archive.ubuntu.com/ubuntu focal-backports/universe amd64 c-n-f Metadata [224 B]\n",
      "Get:40 http://nova.clouds.archive.ubuntu.com/ubuntu focal-backports/multiverse amd64 c-n-f Metadata [116 B]\n",
      "Fetched 18.6 MB in 3s (5508 kB/s)\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "36 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "\n",
      "\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('sudo apt update')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  bridge-utils cgroupfs-mount containerd dns-root-data dnsmasq-base libidn11\n",
      "  pigz runc ubuntu-fan\n",
      "Suggested packages:\n",
      "  ifupdown aufs-tools debootstrap docker-doc rinse zfs-fuse | zfsutils\n",
      "The following NEW packages will be installed:\n",
      "  bridge-utils cgroupfs-mount containerd dns-root-data dnsmasq-base docker.io\n",
      "  libidn11 pigz runc ubuntu-fan\n",
      "0 upgraded, 10 newly installed, 0 to remove and 36 not upgraded.\n",
      "Need to get 69.7 MB of archives.\n",
      "After this operation, 334 MB of additional disk space will be used.\n",
      "Get:1 http://nova.clouds.archive.ubuntu.com/ubuntu focal/universe amd64 pigz amd64 2.4-1 [57.4 kB]\n",
      "Get:2 http://nova.clouds.archive.ubuntu.com/ubuntu focal/main amd64 bridge-utils amd64 1.6-2ubuntu1 [30.5 kB]\n",
      "Get:3 http://nova.clouds.archive.ubuntu.com/ubuntu focal/universe amd64 cgroupfs-mount all 1.4 [6320 B]\n",
      "Get:4 http://nova.clouds.archive.ubuntu.com/ubuntu focal/main amd64 runc amd64 1.0.0~rc10-0ubuntu1 [2549 kB]\n",
      "Get:5 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/main amd64 containerd amd64 1.3.3-0ubuntu2.3 [27.8 MB]\n",
      "Get:6 http://nova.clouds.archive.ubuntu.com/ubuntu focal/main amd64 dns-root-data all 2019052802 [5300 B]\n",
      "Get:7 http://nova.clouds.archive.ubuntu.com/ubuntu focal/main amd64 libidn11 amd64 1.33-2.2ubuntu2 [46.2 kB]\n",
      "Get:8 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/main amd64 dnsmasq-base amd64 2.80-1.1ubuntu1.3 [314 kB]\n",
      "Get:9 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/universe amd64 docker.io amd64 19.03.8-0ubuntu1.20.04.2 [38.9 MB]\n",
      "Get:10 http://nova.clouds.archive.ubuntu.com/ubuntu focal/main amd64 ubuntu-fan all 0.12.13 [34.5 kB]\n",
      "Fetched 69.7 MB in 1s (76.3 MB/s)\n",
      "Selecting previously unselected package pigz.\n",
      "(Reading database ... 63441 files and directories currently installed.)\n",
      "Preparing to unpack .../0-pigz_2.4-1_amd64.deb ...\n",
      "Unpacking pigz (2.4-1) ...\n",
      "Selecting previously unselected package bridge-utils.\n",
      "Preparing to unpack .../1-bridge-utils_1.6-2ubuntu1_amd64.deb ...\n",
      "Unpacking bridge-utils (1.6-2ubuntu1) ...\n",
      "Selecting previously unselected package cgroupfs-mount.\n",
      "Preparing to unpack .../2-cgroupfs-mount_1.4_all.deb ...\n",
      "Unpacking cgroupfs-mount (1.4) ...\n",
      "Selecting previously unselected package runc.\n",
      "Preparing to unpack .../3-runc_1.0.0~rc10-0ubuntu1_amd64.deb ...\n",
      "Unpacking runc (1.0.0~rc10-0ubuntu1) ...\n",
      "Selecting previously unselected package containerd.\n",
      "Preparing to unpack .../4-containerd_1.3.3-0ubuntu2.3_amd64.deb ...\n",
      "Unpacking containerd (1.3.3-0ubuntu2.3) ...\n",
      "Selecting previously unselected package dns-root-data.\n",
      "Preparing to unpack .../5-dns-root-data_2019052802_all.deb ...\n",
      "Unpacking dns-root-data (2019052802) ...\n",
      "Selecting previously unselected package libidn11:amd64.\n",
      "Preparing to unpack .../6-libidn11_1.33-2.2ubuntu2_amd64.deb ...\n",
      "Unpacking libidn11:amd64 (1.33-2.2ubuntu2) ...\n",
      "Selecting previously unselected package dnsmasq-base.\n",
      "Preparing to unpack .../7-dnsmasq-base_2.80-1.1ubuntu1.3_amd64.deb ...\n",
      "Unpacking dnsmasq-base (2.80-1.1ubuntu1.3) ...\n",
      "Selecting previously unselected package docker.io.\n",
      "Preparing to unpack .../8-docker.io_19.03.8-0ubuntu1.20.04.2_amd64.deb ...\n",
      "Unpacking docker.io (19.03.8-0ubuntu1.20.04.2) ...\n",
      "Selecting previously unselected package ubuntu-fan.\n",
      "Preparing to unpack .../9-ubuntu-fan_0.12.13_all.deb ...\n",
      "Unpacking ubuntu-fan (0.12.13) ...\n",
      "Setting up runc (1.0.0~rc10-0ubuntu1) ...\n",
      "Setting up dns-root-data (2019052802) ...\n",
      "Setting up libidn11:amd64 (1.33-2.2ubuntu2) ...\n",
      "Setting up bridge-utils (1.6-2ubuntu1) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (Dialog frontend will not work on a dumb terminal, an emacs shell buffer, or without a controlling terminal.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Setting up pigz (2.4-1) ...\n",
      "Setting up cgroupfs-mount (1.4) ...\n",
      "Setting up containerd (1.3.3-0ubuntu2.3) ...\n",
      "Created symlink /etc/systemd/system/multi-user.target.wants/containerd.service → /lib/systemd/system/containerd.service.\n",
      "Setting up docker.io (19.03.8-0ubuntu1.20.04.2) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (Dialog frontend will not work on a dumb terminal, an emacs shell buffer, or without a controlling terminal.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Adding group `docker' (GID 119) ...\n",
      "Done.\n",
      "Created symlink /etc/systemd/system/sockets.target.wants/docker.socket → /lib/systemd/system/docker.socket.\n",
      "docker.service is a disabled or a static unit, not starting it.\n",
      "Setting up dnsmasq-base (2.80-1.1ubuntu1.3) ...\n",
      "Setting up ubuntu-fan (0.12.13) ...\n",
      "Created symlink /etc/systemd/system/multi-user.target.wants/ubuntu-fan.service → /lib/systemd/system/ubuntu-fan.service.\n",
      "Processing triggers for systemd (245.4-4ubuntu3.5) ...\n",
      "Processing triggers for man-db (2.9.1-1) ...\n",
      "Processing triggers for dbus (1.12.16-2ubuntu2.1) ...\n",
      "Processing triggers for libc-bin (2.31-0ubuntu9.2) ...\n",
      "\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (Dialog frontend will not work on a dumb terminal, an emacs shell buffer, or without a controlling terminal.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('sudo apt-get install -y docker.io')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://nova.clouds.archive.ubuntu.com/ubuntu focal InRelease\n",
      "Hit:2 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates InRelease\n",
      "Hit:3 http://nova.clouds.archive.ubuntu.com/ubuntu focal-backports InRelease\n",
      "Hit:4 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  libcurl4\n",
      "The following NEW packages will be installed:\n",
      "  apt-transport-https\n",
      "The following packages will be upgraded:\n",
      "  curl libcurl4\n",
      "2 upgraded, 1 newly installed, 0 to remove and 34 not upgraded.\n",
      "Need to get 397 kB of archives.\n",
      "After this operation, 161 kB of additional disk space will be used.\n",
      "Get:1 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/universe amd64 apt-transport-https all 2.0.5 [1704 B]\n",
      "Get:2 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/main amd64 curl amd64 7.68.0-1ubuntu2.5 [161 kB]\n",
      "Get:3 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/main amd64 libcurl4 amd64 7.68.0-1ubuntu2.5 [234 kB]\n",
      "Fetched 397 kB in 0s (1844 kB/s)\n",
      "Selecting previously unselected package apt-transport-https.\n",
      "(Reading database ... 63803 files and directories currently installed.)\n",
      "Preparing to unpack .../apt-transport-https_2.0.5_all.deb ...\n",
      "Unpacking apt-transport-https (2.0.5) ...\n",
      "Preparing to unpack .../curl_7.68.0-1ubuntu2.5_amd64.deb ...\n",
      "Unpacking curl (7.68.0-1ubuntu2.5) over (7.68.0-1ubuntu2.4) ...\n",
      "Preparing to unpack .../libcurl4_7.68.0-1ubuntu2.5_amd64.deb ...\n",
      "Unpacking libcurl4:amd64 (7.68.0-1ubuntu2.5) over (7.68.0-1ubuntu2.4) ...\n",
      "Setting up apt-transport-https (2.0.5) ...\n",
      "Setting up libcurl4:amd64 (7.68.0-1ubuntu2.5) ...\n",
      "Setting up curl (7.68.0-1ubuntu2.5) ...\n",
      "Processing triggers for man-db (2.9.1-1) ...\n",
      "Processing triggers for libc-bin (2.31-0ubuntu9.2) ...\n",
      "\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (Dialog frontend will not work on a dumb terminal, an emacs shell buffer, or without a controlling terminal.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('sudo apt-get update && sudo apt-get install -y apt-transport-https curl')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "\n",
      "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deb https://apt.kubernetes.io/ kubernetes-xenial main\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# shell = client1.invoke_shell()\n",
    "# shell.send('cat <<EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list\\n')\n",
    "# shell.send('deb https://apt.kubernetes.io/ kubernetes-xenial main\\n')\n",
    "# shell.send('EOF\\n')\n",
    "\n",
    "\n",
    "stdin, stdout, stderr = client1.exec_command('cat <<EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list\\ndeb https://apt.kubernetes.io/ kubernetes-xenial main\\nEOF\\n')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deb https://apt.kubernetes.io/ kubernetes-xenial main\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('cat /etc/apt/sources.list.d/kubernetes.list')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://nova.clouds.archive.ubuntu.com/ubuntu focal InRelease\n",
      "Hit:2 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates InRelease\n",
      "Hit:3 http://nova.clouds.archive.ubuntu.com/ubuntu focal-backports InRelease\n",
      "Hit:4 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
      "Get:5 https://packages.cloud.google.com/apt kubernetes-xenial InRelease [9383 B]\n",
      "Get:6 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 Packages [46.2 kB]\n",
      "Fetched 55.6 kB in 1s (61.2 kB/s)\n",
      "Reading package lists...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('sudo apt-get update')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  conntrack cri-tools ebtables kubernetes-cni socat\n",
      "Suggested packages:\n",
      "  nftables\n",
      "The following NEW packages will be installed:\n",
      "  conntrack cri-tools ebtables kubeadm kubectl kubelet kubernetes-cni socat\n",
      "0 upgraded, 8 newly installed, 0 to remove and 34 not upgraded.\n",
      "Need to get 70.5 MB of archives.\n",
      "After this operation, 309 MB of additional disk space will be used.\n",
      "Get:1 http://nova.clouds.archive.ubuntu.com/ubuntu focal/main amd64 conntrack amd64 1:1.4.5-2 [30.3 kB]\n",
      "Get:4 http://nova.clouds.archive.ubuntu.com/ubuntu focal/main amd64 ebtables amd64 2.0.11-3build1 [80.3 kB]\n",
      "Get:6 http://nova.clouds.archive.ubuntu.com/ubuntu focal/main amd64 socat amd64 1.7.3.3-2 [323 kB]\n",
      "Get:2 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 cri-tools amd64 1.13.0-01 [8775 kB]\n",
      "Get:3 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubernetes-cni amd64 0.8.7-00 [25.0 MB]\n",
      "Get:5 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubelet amd64 1.21.0-00 [18.8 MB]\n",
      "Get:7 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubectl amd64 1.21.0-00 [8972 kB]\n",
      "Get:8 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubeadm amd64 1.21.0-00 [8544 kB]\n",
      "Fetched 70.5 MB in 3s (27.8 MB/s)\n",
      "Selecting previously unselected package conntrack.\n",
      "(Reading database ... 63807 files and directories currently installed.)\n",
      "Preparing to unpack .../0-conntrack_1%3a1.4.5-2_amd64.deb ...\n",
      "Unpacking conntrack (1:1.4.5-2) ...\n",
      "Selecting previously unselected package cri-tools.\n",
      "Preparing to unpack .../1-cri-tools_1.13.0-01_amd64.deb ...\n",
      "Unpacking cri-tools (1.13.0-01) ...\n",
      "Selecting previously unselected package ebtables.\n",
      "Preparing to unpack .../2-ebtables_2.0.11-3build1_amd64.deb ...\n",
      "Unpacking ebtables (2.0.11-3build1) ...\n",
      "Selecting previously unselected package kubernetes-cni.\n",
      "Preparing to unpack .../3-kubernetes-cni_0.8.7-00_amd64.deb ...\n",
      "Unpacking kubernetes-cni (0.8.7-00) ...\n",
      "Selecting previously unselected package socat.\n",
      "Preparing to unpack .../4-socat_1.7.3.3-2_amd64.deb ...\n",
      "Unpacking socat (1.7.3.3-2) ...\n",
      "Selecting previously unselected package kubelet.\n",
      "Preparing to unpack .../5-kubelet_1.21.0-00_amd64.deb ...\n",
      "Unpacking kubelet (1.21.0-00) ...\n",
      "Selecting previously unselected package kubectl.\n",
      "Preparing to unpack .../6-kubectl_1.21.0-00_amd64.deb ...\n",
      "Unpacking kubectl (1.21.0-00) ...\n",
      "Selecting previously unselected package kubeadm.\n",
      "Preparing to unpack .../7-kubeadm_1.21.0-00_amd64.deb ...\n",
      "Unpacking kubeadm (1.21.0-00) ...\n",
      "Setting up conntrack (1:1.4.5-2) ...\n",
      "Setting up kubectl (1.21.0-00) ...\n",
      "Setting up ebtables (2.0.11-3build1) ...\n",
      "Setting up socat (1.7.3.3-2) ...\n",
      "Setting up cri-tools (1.13.0-01) ...\n",
      "Setting up kubernetes-cni (0.8.7-00) ...\n",
      "Setting up kubelet (1.21.0-00) ...\n",
      "Created symlink /etc/systemd/system/multi-user.target.wants/kubelet.service → /lib/systemd/system/kubelet.service.\n",
      "Setting up kubeadm (1.21.0-00) ...\n",
      "Processing triggers for man-db (2.9.1-1) ...\n",
      "\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (Dialog frontend will not work on a dumb terminal, an emacs shell buffer, or without a controlling terminal.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('sudo apt-get install -y kubelet kubeadm kubectl')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kubelet set on hold.\n",
      "kubeadm set on hold.\n",
      "kubectl set on hold.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('sudo apt-mark hold kubelet kubeadm kubectl')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('sudo swapoff -a')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n",
      "    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n",
      "    inet 127.0.0.1/8 scope host lo\n",
      "       valid_lft forever preferred_lft forever\n",
      "    inet6 ::1/128 scope host \n",
      "       valid_lft forever preferred_lft forever\n",
      "2: ens3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 9000 qdisc fq_codel state UP group default qlen 1000\n",
      "    link/ether fa:16:3e:ec:09:fc brd ff:ff:ff:ff:ff:ff\n",
      "    inet 10.20.4.220/24 brd 10.20.4.255 scope global dynamic ens3\n",
      "       valid_lft 86396sec preferred_lft 86396sec\n",
      "    inet6 fe80::f816:3eff:feec:9fc/64 scope link \n",
      "       valid_lft forever preferred_lft forever\n",
      "3: ens7: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000\n",
      "    link/ether 0c:42:a1:be:8f:e8 brd ff:ff:ff:ff:ff:ff\n",
      "4: ens8: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000\n",
      "    link/ether 0c:42:a1:be:8f:e9 brd ff:ff:ff:ff:ff:ff\n",
      "5: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default \n",
      "    link/ether 02:42:14:49:20:9f brd ff:ff:ff:ff:ff:ff\n",
      "    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\n",
      "       valid_lft forever preferred_lft forever\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('ip address')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The private ip is at ens3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('sudo touch /etc/netplan/60-floating-ip.yaml')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('sudo tee -a /etc/netplan/60-floating-ip.yaml > /dev/null <<EOT\\nnetwork:\\n  version: 2\\n  ethernets:\\n    ens3:\\n      addresses:\\n      - 152.54.15.33/32\\nEOT')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('sudo netplan apply')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n",
      "    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n",
      "    inet 127.0.0.1/8 scope host lo\n",
      "       valid_lft forever preferred_lft forever\n",
      "    inet6 ::1/128 scope host \n",
      "       valid_lft forever preferred_lft forever\n",
      "2: ens3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 9000 qdisc fq_codel state UP group default qlen 1000\n",
      "    link/ether fa:16:3e:ec:09:fc brd ff:ff:ff:ff:ff:ff\n",
      "    inet 152.54.15.33/32 scope global ens3\n",
      "       valid_lft forever preferred_lft forever\n",
      "    inet 10.20.4.220/24 brd 10.20.4.255 scope global dynamic ens3\n",
      "       valid_lft 86398sec preferred_lft 86398sec\n",
      "    inet6 fe80::f816:3eff:feec:9fc/64 scope link \n",
      "       valid_lft forever preferred_lft forever\n",
      "3: ens7: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000\n",
      "    link/ether 0c:42:a1:be:8f:e8 brd ff:ff:ff:ff:ff:ff\n",
      "4: ens8: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000\n",
      "    link/ether 0c:42:a1:be:8f:e9 brd ff:ff:ff:ff:ff:ff\n",
      "5: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default \n",
      "    link/ether 02:42:14:49:20:9f brd ff:ff:ff:ff:ff:ff\n",
      "    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\n",
      "       valid_lft forever preferred_lft forever\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('ip address')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[init] Using Kubernetes version: v1.21.0\n",
      "[preflight] Running pre-flight checks\n",
      "[preflight] Pulling images required for setting up a Kubernetes cluster\n",
      "[preflight] This might take a minute or two, depending on the speed of your internet connection\n",
      "[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'\n",
      "[certs] Using certificateDir folder \"/etc/kubernetes/pki\"\n",
      "[certs] Generating \"ca\" certificate and key\n",
      "[certs] Generating \"apiserver\" certificate and key\n",
      "[certs] apiserver serving cert is signed for DNS names [20e5b9d8-50cd-4ad9-8dc1-930e0772cc4e-n1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 152.54.15.33]\n",
      "[certs] Generating \"apiserver-kubelet-client\" certificate and key\n",
      "[certs] Generating \"front-proxy-ca\" certificate and key\n",
      "[certs] Generating \"front-proxy-client\" certificate and key\n",
      "[certs] Generating \"etcd/ca\" certificate and key\n",
      "[certs] Generating \"etcd/server\" certificate and key\n",
      "[certs] etcd/server serving cert is signed for DNS names [20e5b9d8-50cd-4ad9-8dc1-930e0772cc4e-n1 localhost] and IPs [152.54.15.33 127.0.0.1 ::1]\n",
      "[certs] Generating \"etcd/peer\" certificate and key\n",
      "[certs] etcd/peer serving cert is signed for DNS names [20e5b9d8-50cd-4ad9-8dc1-930e0772cc4e-n1 localhost] and IPs [152.54.15.33 127.0.0.1 ::1]\n",
      "[certs] Generating \"etcd/healthcheck-client\" certificate and key\n",
      "[certs] Generating \"apiserver-etcd-client\" certificate and key\n",
      "[certs] Generating \"sa\" key and public key\n",
      "[kubeconfig] Using kubeconfig folder \"/etc/kubernetes\"\n",
      "[kubeconfig] Writing \"admin.conf\" kubeconfig file\n",
      "[kubeconfig] Writing \"kubelet.conf\" kubeconfig file\n",
      "[kubeconfig] Writing \"controller-manager.conf\" kubeconfig file\n",
      "[kubeconfig] Writing \"scheduler.conf\" kubeconfig file\n",
      "[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n",
      "[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n",
      "[kubelet-start] Starting the kubelet\n",
      "[control-plane] Using manifest folder \"/etc/kubernetes/manifests\"\n",
      "[control-plane] Creating static Pod manifest for \"kube-apiserver\"\n",
      "[control-plane] Creating static Pod manifest for \"kube-controller-manager\"\n",
      "[control-plane] Creating static Pod manifest for \"kube-scheduler\"\n",
      "[etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\"\n",
      "[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s\n",
      "[kubelet-check] Initial timeout of 40s passed.\n",
      "[apiclient] All control plane components are healthy after 104.001903 seconds\n",
      "[upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace\n",
      "[kubelet] Creating a ConfigMap \"kubelet-config-1.21\" in namespace kube-system with the configuration for the kubelets in the cluster\n",
      "[upload-certs] Skipping phase. Please see --upload-certs\n",
      "[mark-control-plane] Marking the node 20e5b9d8-50cd-4ad9-8dc1-930e0772cc4e-n1 as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]\n",
      "[mark-control-plane] Marking the node 20e5b9d8-50cd-4ad9-8dc1-930e0772cc4e-n1 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]\n",
      "[bootstrap-token] Using token: 3aztj9.hoclo44mdgr2ysjh\n",
      "[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles\n",
      "[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes\n",
      "[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials\n",
      "[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token\n",
      "[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster\n",
      "[bootstrap-token] Creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace\n",
      "[kubelet-finalize] Updating \"/etc/kubernetes/kubelet.conf\" to point to a rotatable kubelet client certificate and key\n",
      "[addons] Applied essential addon: CoreDNS\n",
      "[addons] Applied essential addon: kube-proxy\n",
      "\n",
      "Your Kubernetes control-plane has initialized successfully!\n",
      "\n",
      "To start using your cluster, you need to run the following as a regular user:\n",
      "\n",
      "  mkdir -p $HOME/.kube\n",
      "  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n",
      "  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n",
      "\n",
      "Alternatively, if you are the root user, you can run:\n",
      "\n",
      "  export KUBECONFIG=/etc/kubernetes/admin.conf\n",
      "\n",
      "You should now deploy a pod network to the cluster.\n",
      "Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n",
      "  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n",
      "\n",
      "Then you can join any number of worker nodes by running the following on each as root:\n",
      "\n",
      "kubeadm join 152.54.15.33:6443 --token 3aztj9.hoclo44mdgr2ysjh \\\n",
      "\t--discovery-token-ca-cert-hash sha256:d3dcfae8244888e64f4ecaaf1a4e9ca75b13fd5be5271de456c7371267433104 \n",
      "\n",
      "\t[WARNING Service-Docker]: docker service is not enabled, please run 'systemctl enable docker.service'\n",
      "\t[WARNING IsDockerSystemdCheck]: detected \"cgroupfs\" as the Docker cgroup driver. The recommended driver is \"systemd\". Please follow the guide at https://kubernetes.io/docs/setup/cri/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# stdin, stdout, stderr = client1.exec_command('sudo kubeadm init --pod-network-cidr=192.168.0.0/16 --apiserver-advertise-address=0.0.0.0 --apiserver-cert-extra-sans=10.20.4.220,152.54.15.33')\n",
    "stdin, stdout, stderr = client1.exec_command('sudo kubeadm init --pod-network-cidr=192.168.0.0/16 --apiserver-advertise-address=152.54.15.33')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('mkdir -p $HOME/.kube')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cp: overwrite '/home/ubuntu/.kube/config'? \n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('yes | sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('sudo chown $(id -u):$(id -g) $HOME/.kube/config')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configmap/calico-config created\n",
      "customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org created\n",
      "customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org created\n",
      "customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org created\n",
      "customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org created\n",
      "customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org created\n",
      "customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org created\n",
      "customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org created\n",
      "customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org created\n",
      "customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org created\n",
      "customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org created\n",
      "customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org created\n",
      "customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org created\n",
      "customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org created\n",
      "customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org created\n",
      "clusterrole.rbac.authorization.k8s.io/calico-kube-controllers created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers created\n",
      "clusterrole.rbac.authorization.k8s.io/calico-node created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/calico-node created\n",
      "daemonset.apps/calico-node created\n",
      "serviceaccount/calico-node created\n",
      "deployment.apps/calico-kube-controllers created\n",
      "serviceaccount/calico-kube-controllers created\n",
      "\n",
      "Warning: apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('kubectl apply -f https://docs.projectcalico.org/v3.9/manifests/calico.yaml')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                      STATUS   ROLES                  AGE     VERSION\n",
      "20e5b9d8-50cd-4ad9-8dc1-930e0772cc4e-n1   Ready    control-plane,master   4m38s   v1.21.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('kubectl get nodes')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whew. We should be done with the server. Now let's do the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://security.ubuntu.com/ubuntu focal-security InRelease [109 kB]\n",
      "Hit:2 http://nova.clouds.archive.ubuntu.com/ubuntu focal InRelease\n",
      "Get:3 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
      "Get:4 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [619 kB]\n",
      "Get:5 http://nova.clouds.archive.ubuntu.com/ubuntu focal-backports InRelease [101 kB]\n",
      "Get:6 http://nova.clouds.archive.ubuntu.com/ubuntu focal/universe amd64 Packages [8628 kB]\n",
      "Get:7 http://security.ubuntu.com/ubuntu focal-security/main Translation-en [126 kB]\n",
      "Get:8 http://security.ubuntu.com/ubuntu focal-security/main amd64 c-n-f Metadata [7436 B]\n",
      "Get:9 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [181 kB]\n",
      "Get:10 http://security.ubuntu.com/ubuntu focal-security/restricted Translation-en [26.8 kB]\n",
      "Get:11 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 c-n-f Metadata [396 B]\n",
      "Get:12 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [551 kB]\n",
      "Get:13 http://security.ubuntu.com/ubuntu focal-security/universe Translation-en [82.1 kB]\n",
      "Get:14 http://security.ubuntu.com/ubuntu focal-security/universe amd64 c-n-f Metadata [10.7 kB]\n",
      "Get:15 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [14.8 kB]\n",
      "Get:16 http://security.ubuntu.com/ubuntu focal-security/multiverse Translation-en [3160 B]\n",
      "Get:17 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 c-n-f Metadata [340 B]\n",
      "Get:18 http://nova.clouds.archive.ubuntu.com/ubuntu focal/universe Translation-en [5124 kB]\n",
      "Get:19 http://nova.clouds.archive.ubuntu.com/ubuntu focal/universe amd64 c-n-f Metadata [265 kB]\n",
      "Get:20 http://nova.clouds.archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [144 kB]\n",
      "Get:21 http://nova.clouds.archive.ubuntu.com/ubuntu focal/multiverse Translation-en [104 kB]\n",
      "Get:22 http://nova.clouds.archive.ubuntu.com/ubuntu focal/multiverse amd64 c-n-f Metadata [9136 B]\n",
      "Get:23 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [943 kB]\n",
      "Get:24 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/main Translation-en [216 kB]\n",
      "Get:25 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/main amd64 c-n-f Metadata [13.1 kB]\n",
      "Get:26 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [204 kB]\n",
      "Get:27 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/restricted Translation-en [30.4 kB]\n",
      "Get:28 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/restricted amd64 c-n-f Metadata [440 B]\n",
      "Get:29 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [759 kB]\n",
      "Get:30 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/universe Translation-en [162 kB]\n",
      "Get:31 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/universe amd64 c-n-f Metadata [17.0 kB]\n",
      "Get:32 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [21.6 kB]\n",
      "Get:33 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/multiverse Translation-en [5508 B]\n",
      "Get:34 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 c-n-f Metadata [600 B]\n",
      "Get:35 http://nova.clouds.archive.ubuntu.com/ubuntu focal-backports/main amd64 c-n-f Metadata [112 B]\n",
      "Get:36 http://nova.clouds.archive.ubuntu.com/ubuntu focal-backports/restricted amd64 c-n-f Metadata [116 B]\n",
      "Get:37 http://nova.clouds.archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [4032 B]\n",
      "Get:38 http://nova.clouds.archive.ubuntu.com/ubuntu focal-backports/universe Translation-en [1448 B]\n",
      "Get:39 http://nova.clouds.archive.ubuntu.com/ubuntu focal-backports/universe amd64 c-n-f Metadata [224 B]\n",
      "Get:40 http://nova.clouds.archive.ubuntu.com/ubuntu focal-backports/multiverse amd64 c-n-f Metadata [116 B]\n",
      "Fetched 18.6 MB in 4s (5252 kB/s)\n",
      "Reading package lists...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client2.exec_command('sudo apt-get update')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  bridge-utils cgroupfs-mount containerd dns-root-data dnsmasq-base libidn11\n",
      "  pigz runc ubuntu-fan\n",
      "Suggested packages:\n",
      "  ifupdown aufs-tools debootstrap docker-doc rinse zfs-fuse | zfsutils\n",
      "The following NEW packages will be installed:\n",
      "  bridge-utils cgroupfs-mount containerd dns-root-data dnsmasq-base docker.io\n",
      "  libidn11 pigz runc ubuntu-fan\n",
      "0 upgraded, 10 newly installed, 0 to remove and 36 not upgraded.\n",
      "Need to get 69.7 MB of archives.\n",
      "After this operation, 334 MB of additional disk space will be used.\n",
      "Get:1 http://nova.clouds.archive.ubuntu.com/ubuntu focal/universe amd64 pigz amd64 2.4-1 [57.4 kB]\n",
      "Get:2 http://nova.clouds.archive.ubuntu.com/ubuntu focal/main amd64 bridge-utils amd64 1.6-2ubuntu1 [30.5 kB]\n",
      "Get:3 http://nova.clouds.archive.ubuntu.com/ubuntu focal/universe amd64 cgroupfs-mount all 1.4 [6320 B]\n",
      "Get:4 http://nova.clouds.archive.ubuntu.com/ubuntu focal/main amd64 runc amd64 1.0.0~rc10-0ubuntu1 [2549 kB]\n",
      "Get:5 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/main amd64 containerd amd64 1.3.3-0ubuntu2.3 [27.8 MB]\n",
      "Get:6 http://nova.clouds.archive.ubuntu.com/ubuntu focal/main amd64 dns-root-data all 2019052802 [5300 B]\n",
      "Get:7 http://nova.clouds.archive.ubuntu.com/ubuntu focal/main amd64 libidn11 amd64 1.33-2.2ubuntu2 [46.2 kB]\n",
      "Get:8 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/main amd64 dnsmasq-base amd64 2.80-1.1ubuntu1.3 [314 kB]\n",
      "Get:9 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/universe amd64 docker.io amd64 19.03.8-0ubuntu1.20.04.2 [38.9 MB]\n",
      "Get:10 http://nova.clouds.archive.ubuntu.com/ubuntu focal/main amd64 ubuntu-fan all 0.12.13 [34.5 kB]\n",
      "Fetched 69.7 MB in 5s (13.8 MB/s)\n",
      "Selecting previously unselected package pigz.\n",
      "(Reading database ... 63441 files and directories currently installed.)\n",
      "Preparing to unpack .../0-pigz_2.4-1_amd64.deb ...\n",
      "Unpacking pigz (2.4-1) ...\n",
      "Selecting previously unselected package bridge-utils.\n",
      "Preparing to unpack .../1-bridge-utils_1.6-2ubuntu1_amd64.deb ...\n",
      "Unpacking bridge-utils (1.6-2ubuntu1) ...\n",
      "Selecting previously unselected package cgroupfs-mount.\n",
      "Preparing to unpack .../2-cgroupfs-mount_1.4_all.deb ...\n",
      "Unpacking cgroupfs-mount (1.4) ...\n",
      "Selecting previously unselected package runc.\n",
      "Preparing to unpack .../3-runc_1.0.0~rc10-0ubuntu1_amd64.deb ...\n",
      "Unpacking runc (1.0.0~rc10-0ubuntu1) ...\n",
      "Selecting previously unselected package containerd.\n",
      "Preparing to unpack .../4-containerd_1.3.3-0ubuntu2.3_amd64.deb ...\n",
      "Unpacking containerd (1.3.3-0ubuntu2.3) ...\n",
      "Selecting previously unselected package dns-root-data.\n",
      "Preparing to unpack .../5-dns-root-data_2019052802_all.deb ...\n",
      "Unpacking dns-root-data (2019052802) ...\n",
      "Selecting previously unselected package libidn11:amd64.\n",
      "Preparing to unpack .../6-libidn11_1.33-2.2ubuntu2_amd64.deb ...\n",
      "Unpacking libidn11:amd64 (1.33-2.2ubuntu2) ...\n",
      "Selecting previously unselected package dnsmasq-base.\n",
      "Preparing to unpack .../7-dnsmasq-base_2.80-1.1ubuntu1.3_amd64.deb ...\n",
      "Unpacking dnsmasq-base (2.80-1.1ubuntu1.3) ...\n",
      "Selecting previously unselected package docker.io.\n",
      "Preparing to unpack .../8-docker.io_19.03.8-0ubuntu1.20.04.2_amd64.deb ...\n",
      "Unpacking docker.io (19.03.8-0ubuntu1.20.04.2) ...\n",
      "Selecting previously unselected package ubuntu-fan.\n",
      "Preparing to unpack .../9-ubuntu-fan_0.12.13_all.deb ...\n",
      "Unpacking ubuntu-fan (0.12.13) ...\n",
      "Setting up runc (1.0.0~rc10-0ubuntu1) ...\n",
      "Setting up dns-root-data (2019052802) ...\n",
      "Setting up libidn11:amd64 (1.33-2.2ubuntu2) ...\n",
      "Setting up bridge-utils (1.6-2ubuntu1) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (Dialog frontend will not work on a dumb terminal, an emacs shell buffer, or without a controlling terminal.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Setting up pigz (2.4-1) ...\n",
      "Setting up cgroupfs-mount (1.4) ...\n",
      "Setting up containerd (1.3.3-0ubuntu2.3) ...\n",
      "Created symlink /etc/systemd/system/multi-user.target.wants/containerd.service → /lib/systemd/system/containerd.service.\n",
      "Setting up docker.io (19.03.8-0ubuntu1.20.04.2) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (Dialog frontend will not work on a dumb terminal, an emacs shell buffer, or without a controlling terminal.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Adding group `docker' (GID 119) ...\n",
      "Done.\n",
      "Created symlink /etc/systemd/system/sockets.target.wants/docker.socket → /lib/systemd/system/docker.socket.\n",
      "docker.service is a disabled or a static unit, not starting it.\n",
      "Setting up dnsmasq-base (2.80-1.1ubuntu1.3) ...\n",
      "Setting up ubuntu-fan (0.12.13) ...\n",
      "Created symlink /etc/systemd/system/multi-user.target.wants/ubuntu-fan.service → /lib/systemd/system/ubuntu-fan.service.\n",
      "Processing triggers for systemd (245.4-4ubuntu3.5) ...\n",
      "Processing triggers for man-db (2.9.1-1) ...\n",
      "Processing triggers for dbus (1.12.16-2ubuntu2.1) ...\n",
      "Processing triggers for libc-bin (2.31-0ubuntu9.2) ...\n",
      "\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (Dialog frontend will not work on a dumb terminal, an emacs shell buffer, or without a controlling terminal.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client2.exec_command('sudo apt-get install -y docker.io')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
      "Hit:2 http://nova.clouds.archive.ubuntu.com/ubuntu focal InRelease\n",
      "Hit:3 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates InRelease\n",
      "Hit:4 http://nova.clouds.archive.ubuntu.com/ubuntu focal-backports InRelease\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  libcurl4\n",
      "The following NEW packages will be installed:\n",
      "  apt-transport-https\n",
      "The following packages will be upgraded:\n",
      "  curl libcurl4\n",
      "2 upgraded, 1 newly installed, 0 to remove and 34 not upgraded.\n",
      "Need to get 397 kB of archives.\n",
      "After this operation, 161 kB of additional disk space will be used.\n",
      "Get:1 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/universe amd64 apt-transport-https all 2.0.5 [1704 B]\n",
      "Get:2 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/main amd64 curl amd64 7.68.0-1ubuntu2.5 [161 kB]\n",
      "Get:3 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates/main amd64 libcurl4 amd64 7.68.0-1ubuntu2.5 [234 kB]\n",
      "Fetched 397 kB in 1s (613 kB/s)\n",
      "Selecting previously unselected package apt-transport-https.\n",
      "(Reading database ... 63803 files and directories currently installed.)\n",
      "Preparing to unpack .../apt-transport-https_2.0.5_all.deb ...\n",
      "Unpacking apt-transport-https (2.0.5) ...\n",
      "Preparing to unpack .../curl_7.68.0-1ubuntu2.5_amd64.deb ...\n",
      "Unpacking curl (7.68.0-1ubuntu2.5) over (7.68.0-1ubuntu2.4) ...\n",
      "Preparing to unpack .../libcurl4_7.68.0-1ubuntu2.5_amd64.deb ...\n",
      "Unpacking libcurl4:amd64 (7.68.0-1ubuntu2.5) over (7.68.0-1ubuntu2.4) ...\n",
      "Setting up apt-transport-https (2.0.5) ...\n",
      "Setting up libcurl4:amd64 (7.68.0-1ubuntu2.5) ...\n",
      "Setting up curl (7.68.0-1ubuntu2.5) ...\n",
      "Processing triggers for man-db (2.9.1-1) ...\n",
      "Processing triggers for libc-bin (2.31-0ubuntu9.2) ...\n",
      "\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (Dialog frontend will not work on a dumb terminal, an emacs shell buffer, or without a controlling terminal.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client2.exec_command('sudo apt-get update && sudo apt-get install -y apt-transport-https curl')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "\n",
      "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client2.exec_command('curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deb https://apt.kubernetes.io/ kubernetes-xenial main\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client2.exec_command('cat <<EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list\\ndeb https://apt.kubernetes.io/ kubernetes-xenial main\\nEOF\\n')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deb https://apt.kubernetes.io/ kubernetes-xenial main\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client2.exec_command('cat /etc/apt/sources.list.d/kubernetes.list')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://nova.clouds.archive.ubuntu.com/ubuntu focal InRelease\n",
      "Hit:2 http://nova.clouds.archive.ubuntu.com/ubuntu focal-updates InRelease\n",
      "Hit:3 http://nova.clouds.archive.ubuntu.com/ubuntu focal-backports InRelease\n",
      "Hit:4 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
      "Get:5 https://packages.cloud.google.com/apt kubernetes-xenial InRelease [9383 B]\n",
      "Get:6 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 Packages [46.2 kB]\n",
      "Fetched 55.6 kB in 1s (40.0 kB/s)\n",
      "Reading package lists...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client2.exec_command('sudo apt-get update')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  conntrack cri-tools ebtables kubernetes-cni socat\n",
      "Suggested packages:\n",
      "  nftables\n",
      "The following NEW packages will be installed:\n",
      "  conntrack cri-tools ebtables kubeadm kubectl kubelet kubernetes-cni socat\n",
      "0 upgraded, 8 newly installed, 0 to remove and 34 not upgraded.\n",
      "Need to get 70.5 MB of archives.\n",
      "After this operation, 309 MB of additional disk space will be used.\n",
      "Get:1 http://nova.clouds.archive.ubuntu.com/ubuntu focal/main amd64 conntrack amd64 1:1.4.5-2 [30.3 kB]\n",
      "Get:4 http://nova.clouds.archive.ubuntu.com/ubuntu focal/main amd64 ebtables amd64 2.0.11-3build1 [80.3 kB]\n",
      "Get:8 http://nova.clouds.archive.ubuntu.com/ubuntu focal/main amd64 socat amd64 1.7.3.3-2 [323 kB]\n",
      "Get:2 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 cri-tools amd64 1.13.0-01 [8775 kB]\n",
      "Get:3 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubernetes-cni amd64 0.8.7-00 [25.0 MB]\n",
      "Get:5 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubelet amd64 1.21.0-00 [18.8 MB]\n",
      "Get:6 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubectl amd64 1.21.0-00 [8972 kB]\n",
      "Get:7 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubeadm amd64 1.21.0-00 [8544 kB]\n",
      "Fetched 70.5 MB in 4s (18.5 MB/s)\n",
      "Selecting previously unselected package conntrack.\n",
      "(Reading database ... 63807 files and directories currently installed.)\n",
      "Preparing to unpack .../0-conntrack_1%3a1.4.5-2_amd64.deb ...\n",
      "Unpacking conntrack (1:1.4.5-2) ...\n",
      "Selecting previously unselected package cri-tools.\n",
      "Preparing to unpack .../1-cri-tools_1.13.0-01_amd64.deb ...\n",
      "Unpacking cri-tools (1.13.0-01) ...\n",
      "Selecting previously unselected package ebtables.\n",
      "Preparing to unpack .../2-ebtables_2.0.11-3build1_amd64.deb ...\n",
      "Unpacking ebtables (2.0.11-3build1) ...\n",
      "Selecting previously unselected package kubernetes-cni.\n",
      "Preparing to unpack .../3-kubernetes-cni_0.8.7-00_amd64.deb ...\n",
      "Unpacking kubernetes-cni (0.8.7-00) ...\n",
      "Selecting previously unselected package socat.\n",
      "Preparing to unpack .../4-socat_1.7.3.3-2_amd64.deb ...\n",
      "Unpacking socat (1.7.3.3-2) ...\n",
      "Selecting previously unselected package kubelet.\n",
      "Preparing to unpack .../5-kubelet_1.21.0-00_amd64.deb ...\n",
      "Unpacking kubelet (1.21.0-00) ...\n",
      "Selecting previously unselected package kubectl.\n",
      "Preparing to unpack .../6-kubectl_1.21.0-00_amd64.deb ...\n",
      "Unpacking kubectl (1.21.0-00) ...\n",
      "Selecting previously unselected package kubeadm.\n",
      "Preparing to unpack .../7-kubeadm_1.21.0-00_amd64.deb ...\n",
      "Unpacking kubeadm (1.21.0-00) ...\n",
      "Setting up conntrack (1:1.4.5-2) ...\n",
      "Setting up kubectl (1.21.0-00) ...\n",
      "Setting up ebtables (2.0.11-3build1) ...\n",
      "Setting up socat (1.7.3.3-2) ...\n",
      "Setting up cri-tools (1.13.0-01) ...\n",
      "Setting up kubernetes-cni (0.8.7-00) ...\n",
      "Setting up kubelet (1.21.0-00) ...\n",
      "Created symlink /etc/systemd/system/multi-user.target.wants/kubelet.service → /lib/systemd/system/kubelet.service.\n",
      "Setting up kubeadm (1.21.0-00) ...\n",
      "Processing triggers for man-db (2.9.1-1) ...\n",
      "\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (Dialog frontend will not work on a dumb terminal, an emacs shell buffer, or without a controlling terminal.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client2.exec_command('sudo apt-get install -y kubelet kubeadm kubectl')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kubelet set on hold.\n",
      "kubeadm set on hold.\n",
      "kubectl set on hold.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client2.exec_command('sudo apt-mark hold kubelet kubeadm kubectl')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client2.exec_command('sudo swapoff -a')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup is complete. We were just running a script one command after the other. Now we need to do the join command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did sudo nano /etc/netplan/60-floating-ip.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also did sudo nano /etc/systemd/system/kubelet.service.d/10-kubeadm.conf. We set --node-ip to the public ip of the client node. It can now bind to it because of the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[preflight] Running pre-flight checks\n",
      "[preflight] Reading configuration from the cluster...\n",
      "[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'\n",
      "[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n",
      "[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n",
      "[kubelet-start] Starting the kubelet\n",
      "[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...\n",
      "\n",
      "This node has joined the cluster:\n",
      "* Certificate signing request was sent to apiserver and a response was received.\n",
      "* The Kubelet was informed of the new secure connection details.\n",
      "\n",
      "Run 'kubectl get nodes' on the control-plane to see this node join the cluster.\n",
      "\n",
      "\n",
      "\t[WARNING Service-Docker]: docker service is not enabled, please run 'systemctl enable docker.service'\n",
      "\t[WARNING IsDockerSystemdCheck]: detected \"cgroupfs\" as the Docker cgroup driver. The recommended driver is \"systemd\". Please follow the guide at https://kubernetes.io/docs/setup/cri/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client2.exec_command('sudo kubeadm join 152.54.15.33:6443 --token 3aztj9.hoclo44mdgr2ysjh --discovery-token-ca-cert-hash sha256:d3dcfae8244888e64f4ecaaf1a4e9ca75b13fd5be5271de456c7371267433104')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                      STATUS   ROLES                  AGE   VERSION\n",
      "20e5b9d8-50cd-4ad9-8dc1-930e0772cc4e-n1   Ready    control-plane,master   18m   v1.21.0\n",
      "d0cf0b1c-58da-4a5c-9874-724772670441-n2   Ready    <none>                 15s   v1.21.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('kubectl get nodes')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the client node! Awesome!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's run an application on the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/hello-node created\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('kubectl create deployment hello-node --image=k8s.gcr.io/echoserver:1.4')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service/hello-node exposed\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('kubectl expose deployment hello-node --type=ClusterIP --port=8080')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('kubectl port-forward --address 0.0.0.0 service/hello-node 8080:8080 > /dev/null 2>&1 &')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n",
      "    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n",
      "    inet 127.0.0.1/8 scope host lo\n",
      "       valid_lft forever preferred_lft forever\n",
      "    inet6 ::1/128 scope host \n",
      "       valid_lft forever preferred_lft forever\n",
      "2: ens3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 9000 qdisc fq_codel state UP group default qlen 1000\n",
      "    link/ether fa:16:3e:68:f3:5e brd ff:ff:ff:ff:ff:ff\n",
      "    inet 10.20.4.61/24 brd 10.20.4.255 scope global dynamic ens3\n",
      "       valid_lft 63005sec preferred_lft 63005sec\n",
      "    inet6 fe80::f816:3eff:fe68:f35e/64 scope link \n",
      "       valid_lft forever preferred_lft forever\n",
      "3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default \n",
      "    link/ether 02:42:43:a1:e1:4a brd ff:ff:ff:ff:ff:ff\n",
      "    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\n",
      "       valid_lft forever preferred_lft forever\n",
      "13: cali5eefea563d2@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1440 qdisc noqueue state UP group default \n",
      "    link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netnsid 0\n",
      "    inet6 fe80::ecee:eeff:feee:eeee/64 scope link \n",
      "       valid_lft forever preferred_lft forever\n",
      "16: calic031173863e@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1440 qdisc noqueue state UP group default \n",
      "    link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netnsid 1\n",
      "    inet6 fe80::ecee:eeff:feee:eeee/64 scope link \n",
      "       valid_lft forever preferred_lft forever\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client2.exec_command('ip address')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE\n",
      "hello-node   ClusterIP   10.111.57.137   <none>        8080/TCP   14m\n",
      "kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP    13h\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('kubectl get services')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                      STATUS   ROLES                  AGE     VERSION   INTERNAL-IP     EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME\n",
      "20e5b9d8-50cd-4ad9-8dc1-930e0772cc4e-n1   Ready    control-plane,master   15h     v1.21.0   10.20.4.220     <none>        Ubuntu 20.04.2 LTS   5.4.0-70-generic   docker://19.3.8\n",
      "d0cf0b1c-58da-4a5c-9874-724772670441-n2   Ready    <none>                 3m25s   v1.21.0   198.129.61.38   <none>        Ubuntu 20.04.2 LTS   5.4.0-70-generic   docker://19.3.8\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('kubectl get nodes -o wide')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test if the application is running. Let's do this on the master node itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIENT VALUES:\n",
      "client_address=127.0.0.1\n",
      "command=GET\n",
      "real path=/\n",
      "query=nil\n",
      "request_version=1.1\n",
      "request_uri=http://localhost:8080/\n",
      "\n",
      "SERVER VALUES:\n",
      "server_version=nginx: 1.10.0 - lua: 10001\n",
      "\n",
      "HEADERS RECEIVED:\n",
      "accept=*/*\n",
      "host=localhost:8080\n",
      "user-agent=curl/7.68.0\n",
      "BODY:\n",
      "-no body in request-\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   286    0   286    0     0   1324      0 --:--:-- --:--:-- --:--:--  1324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdin, stdout, stderr = client1.exec_command('curl localhost:8080')\n",
    "print(stdout.read().decode(\"utf-8\"))\n",
    "print(stderr.read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's do the same test from our notebook. Same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "CLIENT VALUES:\n",
      "client_address=127.0.0.1\n",
      "command=GET\n",
      "real path=/\n",
      "query=nil\n",
      "request_version=1.1\n",
      "request_uri=http://152.54.15.33:8080/\n",
      "\n",
      "SERVER VALUES:\n",
      "server_version=nginx: 1.10.0 - lua: 10001\n",
      "\n",
      "HEADERS RECEIVED:\n",
      "accept=*/*\n",
      "accept-encoding=gzip, deflate\n",
      "connection=keep-alive\n",
      "host=152.54.15.33:8080\n",
      "user-agent=python-requests/2.25.1\n",
      "BODY:\n",
      "-no body in request-\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "x = requests.get('http://152.54.15.33:8080')\n",
    "print(x.status_code)\n",
    "print(x.content.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The echo server is working. Experiment complete :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Status Status.OK\n",
      "Response received {'value': None}\n"
     ]
    }
   ],
   "source": [
    "status, result = orchestrator_proxy.delete(token=fabric_id_token, slice_id=slice_id)\n",
    "\n",
    "print(\"Response Status {}\".format(status))\n",
    "print(\"Response received {}\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
